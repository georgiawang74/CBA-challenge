# -*- coding: utf-8 -*-
"""Random Forest Live -24hours.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TahAgNwZtX4BeSweGyZ_BAwfX3tLXhb6
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

CSV_PATH = "final_hourly.csv"

df = pd.read_csv(CSV_PATH)

#making sure Datetime column is correct
dt_candidates = [c for c in df.columns if c.lower() in ("timestamp","datetime","date","time","dt")]
dt_col = dt_candidates[0] if dt_candidates else df.columns[0]
df[dt_col] = pd.to_datetime(df[dt_col], errors="coerce", utc=True)
df = df.dropna(subset=[dt_col]).sort_values(dt_col).reset_index(drop=True)


#Since we're preidcting spot, we focus on the "Close" column

if "Close" in df.columns:
    target_col = "Close"

#Feature engineering, only using data at time t-1 or earlier, prevent leakage of past data into future predictions

df["spot_lag1"] = df[target_col].shift(1) #e.g. t-1
df["spot_lag2"] = df[target_col].shift(2)

ret = df[target_col].pct_change()

df["ma20"] = df[target_col].rolling(20, min_periods=10).mean().shift(1)     # moving average, helps exclude current price t, only include prices up to t-1
df["vol5"] = ret.rolling(5, min_periods=5).std().shift(1)                   # only inlcudes past volatility

hour = pd.to_datetime(df[dt_col], utc=True).dt.hour

df["y_next"] = df[target_col].shift(-1)

features = [
    "spot_lag1","spot_lag2",
    "ma20","vol5"
]

#removed, commodities, return lag and time cyclicality (deemed not important)

# Drop rows where any feature or target is NA (created by shifts/rolls)
dfm = df.dropna(subset=features + ["y_next"]).copy()
X = dfm[features]
y = dfm["y_next"]
time_idx = dfm[dt_col]

print(f"Dataset info: {len(dfm)} observations with {len(features)} features")
print(f"Features: {features}")

#Splitting data into training (70%) and testing (30%)

split_idx = int(len(dfm) * 0.7)
print(f"Walk-forward testing starts from observation {split_idx} ({len(dfm) - split_idx} predictions)")

#Walk-forward simulation, rollowing window --> imitate live data
# - will train on last (N) rows instead of full history
# - refit on every "Refit_every" steps (accounts any market changes with live data)

REFIT_EVERY  = 48     # retrain ~every 2 days if hourly
ROLLING_SIZE = 2000   # use last N rows as training window
MIN_TRAIN    = max(500, int(len(X) * 0.4))  # warmup before predicting


print(f"\nWalk-forward parameters:")
print(f"Refit every: {REFIT_EVERY} hours")
print(f"Rolling window: {ROLLING_SIZE} hours")
print(f"Minimum training: {MIN_TRAIN} hours")

# Precompute arrays for speed
X_np    = X.to_numpy(dtype=np.float32)
y_np    = y.to_numpy(dtype=np.float32)
time_np = pd.to_datetime(time_idx).to_numpy()

wf_preds, wf_true, wf_time = [], [], []
rf_wf = None

# Main model architecture used throughout
def _new_model():
    return RandomForestRegressor(n_estimators=120, random_state=42, n_jobs=-1)

print(f"\nStarting walk-forward simulation...")

for i in range(split_idx, len(X_np)):
    if i < MIN_TRAIN:
        continue

    # Rolling training window [start:i)
    start = max(0, i - ROLLING_SIZE)

    # Refit periodically
    if (i == split_idx) or ((i - split_idx) % REFIT_EVERY == 0) or (rf_wf is None):
        rf_wf = _new_model()
        rf_wf.fit(X_np[start:i, :], y_np[start:i])
        print(f"  Retrained at step {i}: using data from {start} to {i}")

    # Predict y[i] using features at i-1 (past-only features)
    yhat = float(rf_wf.predict(X_np[[i - 1], :])[0])

    wf_preds.append(yhat)
    wf_true.append(float(y_np[i]))
    wf_time.append(time_np[i])

# Evaluate & plot
if wf_preds:
    wf_preds = np.array(wf_preds); wf_true = np.array(wf_true)

    rmse_wf = np.sqrt(mean_squared_error(wf_true, wf_preds))
    mae_wf  = mean_absolute_error(wf_true, wf_preds)
    r2_wf   = r2_score(wf_true, wf_preds)

    print(f"\n=== Walk-Forward Performance (Main Results) ===")
    print(f"Samples: {len(wf_true)}")
    print(f"RMSE   : {rmse_wf:.6f}")
    print(f"MAE    : {mae_wf:.6f}")
    print(f"R²     : {r2_wf:.4f}")

    plt.figure(figsize=(12,5))
    plt.plot(wf_time, wf_true, label="Actual next hour")
    plt.plot(wf_time, wf_preds, label="Predicted next hour", linestyle="--")
    plt.title("AUDUSD spot — Walk-Forward Predictions")
    plt.xlabel("Time"); plt.ylabel("Spot"); plt.legend(); plt.grid(True)
    plt.gcf().autofmt_xdate(); plt.show()

    plt.figure(figsize=(6,6))
    plt.scatter(wf_true, wf_preds, alpha=0.6)
    lo, hi = float(min(wf_true.min(), wf_preds.min())), float(max(wf_true.max(), wf_preds.max()))
    plt.plot([lo, hi], [lo, hi], linestyle="--", color = 'red', linewidth=2)
    plt.xlabel("Actual Spot"); plt.ylabel("Predicted Spot")
    plt.title("Actual vs Predicted Spot (walk-forward)")
    plt.grid(True); plt.show()

    # Feature importances from most recent model
    if rf_wf is not None:
        importances = pd.Series(rf_wf.feature_importances_, index=features).sort_values(ascending=False)
        print("\n=== FEATURE IMPORTANCE ANALYSIS ===")
        print("Feature importances (most recent model):\n", importances)

else:
    print("\nWalk-forward skipped (not enough data after warmup).") #de-bugging just in case

#Creating some trading signals / calc confidence levels / moevment

import numpy as np, math, json, os
os.makedirs("outputs", exist_ok=True)

# 1) Estimate forecast noise from walk-forward residuals (in pips)
if len(wf_true) and len(wf_preds):
    resid_pips = (np.array(wf_true) - np.array(wf_preds)) * 1e4
    sigma_pips = float(np.std(resid_pips[-500:])) if len(resid_pips) > 50 else float(np.std(resid_pips))
else:
    sigma_pips = 2.0  # fallback

# 2) Fit a fresh model on the most recent rolling window and predict the *next* hour
start = max(0, len(X) - ROLLING_SIZE)
model_now = _new_model()  # Same architecture as walk-forward
model_now.fit(X.iloc[start:], y.iloc[start:])
last_spot = float(df[target_col].iloc[-1])  # current price
yhat_next = float(model_now.predict(X.iloc[[-1]])[0])  # next-hour forecast
pred_pips = (yhat_next - last_spot) * 1e4

# 3) Noise gate (costs + uncertainty) + simple momentum filter
SPREAD_PIPS = 1.0
K_COST, K_SIGMA = 1.5, 0.50
threshold = K_COST * SPREAD_PIPS + K_SIGMA * sigma_pips #threshold for determining trade signal is here

r = df[target_col].pct_change()
recent_mo = float(r.tail(3).sum())  # >0 up, <0 down
mo_ok = (np.sign(pred_pips) == np.sign(recent_mo)) or (abs(pred_pips)/(sigma_pips+1e-9) >= 1.25)

signal = "flat"
if (abs(pred_pips) > threshold) and mo_ok:
    signal = "long" if pred_pips > 0 else "short"

# 4) Confidence (probability the move beats costs under Normal residuals)
z_cost = (abs(pred_pips) - SPREAD_PIPS) / (sigma_pips + 1e-9)
p_edge = 0.5 * (1.0 + math.erf(z_cost / math.sqrt(2)))   # Φ(z)
confidence = float(np.clip(2*(p_edge - 0.5), 0, 1))       # map to 0..1

#TP/SL from predicted move + residual sigma
K_TP, K_SL = 1.0, 0.75
tp = sl = None
if signal != "flat":
    tp = last_spot + (np.sign(pred_pips) * (abs(pred_pips) + K_TP*sigma_pips)) / 1e4 #when to take profit
    sl = last_spot + (-np.sign(pred_pips) * K_SL*sigma_pips) / 1e4 # when to take loss

print(f"\n=== Current Trading Signal ===")
print(f"Signal: {signal} | Confidence: {confidence:.2f} | Pred move: {pred_pips:.1f} pips | "
      f"sigma≈{sigma_pips:.1f} | threshold≈{threshold:.1f}")

# 5) Persist for your "running system"
out = {
  "timestamp": str(df[dt_col].iloc[-1]),
  "spot": round(last_spot, 6),
  "pred_next_hour": round(yhat_next, 6),
  "pred_move_pips": round(pred_pips, 1),
  "signal": signal,
  "confidence": round(confidence, 2),
  "tp": (round(tp, 6) if tp is not None else None),
  "sl": (round(sl, 6) if sl is not None else None),
  "assumptions": {"spread_pips": SPREAD_PIPS, "sigma_pips": round(sigma_pips, 1), "momentum_ok": bool(mo_ok)}
}
json.dump(out, open("outputs/latest_signal.json","w"), indent=2)

#Prediction of next 24 hours based on training model features + signal generation
#Since our original model is predicting every hour, we need a model that retrains itself every hour so it recognises any new patterns etc
#So we predict the next 24 hours with the same structure/ features etc but just one RF per hour
def next_24h_path(X, y, n_estimators=120, min_rows=200):
    """Train one RF per horizon h=1..24 on the same lagged features; predict from the latest row."""
    preds, horizons = [], []
    X_now = X.iloc[[-1]]  # inetgrating features in walkforward step
    for h in range(1, 25):
        y_h = y.shift(-(h-1))  # target h steps ahead
        valid = (~X.isna().any(axis=1)) & (~y_h.isna())
        Xh, yh = X.loc[valid], y_h.loc[valid]
        if len(Xh) < min_rows:
            preds.append(np.nan); horizons.append(h); continue
        rf_h = RandomForestRegressor(n_estimators=n_estimators, random_state=42, n_jobs=-1) #using same RF structure as training model
        rf_h.fit(Xh, yh)
        preds.append(float(rf_h.predict(X_now)[0])); horizons.append(h)
    path = pd.DataFrame({"horizon_hours": horizons, "predicted_spot": preds})
    path.to_csv("outputs/next24_hourly_forecast.csv", index=False)
    print("\nSaved next-24h path -> outputs/next24_hourly_forecast.csv")

# call it:
next_24h_path(X, y)

# Generate signals for 24h forecast --> same as training model
import pandas as pd, numpy as np
f = pd.read_csv("outputs/next24_hourly_forecast.csv")  # horizon_hours, predicted_spot
last_spot = float(df[target_col].iloc[-1])

f["move_pips"] = (f["predicted_spot"] - last_spot) * 1e4
SPREAD_PIPS, SIGMA_PIPS = 1.0, sigma_pips  # reuse sigma from above
THRESH = 1.5*SPREAD_PIPS + 0.75*SIGMA_PIPS

f["signal"] = np.where(abs(f["move_pips"]) > THRESH,
                       np.where(f["move_pips"] > 0, "long", "short"),
                       "flat")
f["confidence"] = np.clip(abs(f["move_pips"]) / (2*SIGMA_PIPS + 1e-9), 0, 1)
f.to_csv("outputs/next24_hourly_forecast_with_signals.csv", index=False)

print("Saved -> outputs/next24_hourly_forecast_with_signals.csv")
print(f.head(10))

# Plotting the predicted next 24 hours
df_forecast = pd.read_csv("outputs/next24_hourly_forecast.csv")

# Y = predicted spot (numeric), X = hour ahead (1..24) or the column if present
y_forecast = pd.to_numeric(df_forecast["predicted_spot"], errors="coerce")
x_forecast = df_forecast["horizon_hours"] if "horizon_hours" in df_forecast.columns else range(1, len(y_forecast) + 1)

# Keep only non-NaN predictions so x and y match
check = y_forecast.notna()
x_forecast = list(pd.Series(x_forecast)[check])   # guarantees same length as y
y_forecast = list(y_forecast[check])

plt.figure(figsize=(10,5))
plt.plot(x_forecast, y_forecast, marker="o")
plt.title("Predicted Spot vs Hour Ahead (Next 24h)")
plt.xlabel("Hour Ahead")
plt.ylabel("Predicted Spot")
plt.grid(True)
plt.tight_layout()
plt.show()

#Using the walkforward model to predict each horizon hour

def train_horizon_model_with_walkforward(X, y, horizon_hours, features):

    # Create target for this horizon
    y_h = y.shift(-horizon_hours)

    # Clean data for this horizon
    valid_mask = (~X.isna().any(axis=1)) & (~y_h.isna())
    X_h = X.loc[valid_mask]
    y_h = y_h.loc[valid_mask]

    if len(X_h) < 500:  # Not enough data for this horizon
        return None, None, None

    # Apply walk-forward methodology
    split_idx = int(len(X_h) * 0.7)

    # Use same walk-forward parameters as main system
    REFIT_EVERY = 48
    ROLLING_SIZE = 2000
    MIN_TRAIN = max(500, int(len(X_h) * 0.4))

    X_np = X_h.to_numpy(dtype=np.float32)
    y_np = y_h.to_numpy(dtype=np.float32)

    wf_preds, wf_true = [], []
    model_h = None

    # Same model architecture as main system
    def _new_model():
        return RandomForestRegressor(n_estimators=120, random_state=42, n_jobs=-1)

    # Walk-forward validation for this horizon
    for i in range(split_idx, len(X_np)):
        if i < MIN_TRAIN:
            continue

        start = max(0, i - ROLLING_SIZE)

        # Refit using walkforward methodology
        if (i == split_idx) or ((i - split_idx) % REFIT_EVERY == 0) or (model_h is None):
            model_h = _new_model()
            model_h.fit(X_np[start:i, :], y_np[start:i])

        # Predict
        yhat = float(model_h.predict(X_np[[i - 1], :])[0])
        wf_preds.append(yhat)
        wf_true.append(float(y_np[i]))

    # Calculate performance using same metrics
    if len(wf_preds) > 0:
        wf_preds = np.array(wf_preds)
        wf_true = np.array(wf_true)
        r2_h = r2_score(wf_true, wf_preds)
        mae_h = mean_absolute_error(wf_true, wf_preds)

        # Train final model on most recent data
        final_start = max(0, len(X_h) - ROLLING_SIZE)
        final_model = _new_model()
        final_model.fit(X_h.iloc[final_start:], y_h.iloc[final_start:])

        return final_model, r2_h, mae_h

    return None, None, None

# Apply walkforward methodology to key horizons (not all 24 - too slow for demo)
key_horizons = [1, 4, 8, 12, 16, 20, 24]  # Representative hours
horizon_models = {}
horizon_performance = {}

print("Training horizon models using walk-forward methodology:")

for h in key_horizons:
    print(f"\nTraining {h}-hour model...")
    model_h, r2_h, mae_h = train_horizon_model_with_walkforward(X, y, h, features)

    if model_h is not None:
        horizon_models[h] = model_h
        horizon_performance[h] = {'r2': r2_h, 'mae': mae_h}
        print(f"  {h}h model: R² = {r2_h:.3f}, MAE = {mae_h:.6f}")
    else:
        print(f"  {h}h model: Insufficient data")

# Generate path using validated model
print(f"\n=== Generating 24h Path ===")

if len(horizon_models) > 0:
    current_features = X.iloc[[-1]]
    current_spot = float(df[target_col].iloc[-1])

    path_predictions = []

    for h in range(1, 25):
        if h in horizon_models:
            # Use validated model for this horizon
            pred_spot = float(horizon_models[h].predict(current_features)[0])
        else:
            # Interpolate between validated models
            lower_h = max([k for k in horizon_models.keys() if k <= h], default=1)
            upper_h = min([k for k in horizon_models.keys() if k >= h], default=24)

            if lower_h == upper_h:
                pred_spot = float(horizon_models[lower_h].predict(current_features)[0])
            else:
                # Linear interpolation between validated models
                lower_pred = float(horizon_models[lower_h].predict(current_features)[0])
                upper_pred = float(horizon_models[upper_h].predict(current_features)[0])
                weight = (h - lower_h) / (upper_h - lower_h)
                pred_spot = lower_pred + weight * (upper_pred - lower_pred)

        move_pips = (pred_spot - current_spot) * 1e4

        path_predictions.append({
            'horizon_hours': h,
            'predicted_spot': pred_spot,
            'move_pips': move_pips,
            'model_type': 'validated' if h in horizon_models else 'interpolated'
        })

    path_forecast = pd.DataFrame(path_predictions)

    # Apply same signal generation logic
    SPREAD_PIPS, SIGMA_PIPS = 1.0, sigma_pips
    THRESH = 1.5*SPREAD_PIPS + 0.75*SIGMA_PIPS

    path_forecast["signal"] = np.where(
        abs(path_forecast["move_pips"]) > THRESH,
        np.where(path_forecast["move_pips"] > 0, "long", "short"),
        "flat"
    )
    path_forecast["confidence"] = np.clip(
        abs(path_forecast["move_pips"]) / (2*SIGMA_PIPS + 1e-9), 0, 1
    )


    path_forecast.to_csv("outputs/next24_hourly_forecast.csv", index=False)
    path_forecast.to_csv("outputs/next24_hourly_forecast_with_signals.csv", index=False)

    print("Saved -> outputs/next24_hourly_forecast_with_signals.csv")
    print(path_forecast.head(10))

    y_forecast = path_forecast["predicted_spot"].values
    x_forecast = path_forecast["horizon_hours"].values

    plt.figure(figsize=(12,6))

    # Color-code by model type
    validated_mask = path_forecast['model_type'] == 'validated'

    plt.plot(x_forecast[validated_mask], y_forecast[validated_mask],
             'o-', linewidth=2, markersize=6, label="Walk-Forward Validated", color='blue')
    plt.plot(x_forecast[~validated_mask], y_forecast[~validated_mask],
             'o-', linewidth=1, markersize=4, label="Interpolated", color='green', alpha=0.7)


    # Show validation points
    for h in horizon_models.keys():
        plt.axvline(x=h, color='green', alpha=0.3, linestyle=':')

    price_range = y_forecast.max() - y_forecast.min()
    plt.title(f"24-Hour Path Using Walk-Forward Methodology\nRange: {price_range*1e4:.1f} pips")
    plt.xlabel("Hours Ahead")
    plt.ylabel("Predicted Spot")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()


    for h, perf in horizon_performance.items():
        print(f"  {h}h model: R² = {perf['r2']:.3f} (walk-forward validated)")

    print(f"Signal logic: threshold system (±{THRESH:.1f} pips)")
    print(f"Same features: {features}")

else:
    print("No horizon models could be trained - insufficient data")